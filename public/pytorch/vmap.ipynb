{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import vmap # If using PyTorch 1.8 or later\n",
    "# from torch._vmap_internals import vmap # If using PyTorch 1.7\n",
    "from typing import Callable"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "def jacobian(fun, x) -> torch.Tensor:\n",
    "  x = x.detach().requires_grad_()\n",
    "  y = fun(x)\n",
    "  vjp = lambda v: torch.autograd.grad(y, x, v)[0]\n",
    "\n",
    "  vs = torch.eye(y.numel())\\\n",
    "            .view(y.numel(), *y.shape)\n",
    "  result = vmap(vjp)(vs)\n",
    "  return result.detach()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[3., 0., 0.],\n        [0., 3., 0.],\n        [0., 0., 3.]])"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute jacobian(g) via vmap and autograd.grad\n",
    "f = lambda x: x ** 3\n",
    "jacobian(f, torch.ones(3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "def hessian(f: Callable, x: torch.Tensor) ->  torch.Tensor:\n",
    "    def first_grad(x: torch.Tensor):\n",
    "        y = f(x)\n",
    "        assert y.dim() == 0  # hessian only defined on scalar-valued function\n",
    "        return torch.autograd.grad(y, x, create_graph=True)[0]\n",
    "\n",
    "    return jacobian(first_grad, x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[6., 0., 0.],\n        [0., 6., 0.],\n        [0., 0., 6.]])"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute hessian(g) via vmap and autograd.grad\n",
    "g = lambda x: (x ** 3).sum()\n",
    "hessian(g, torch.ones(3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[5., 5.],\n        [5., 5.],\n        [5., 5.]])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot                     # [ D ] , [ D ]  -> []\n",
    "vdot = torch.vmap(torch.dot)  # [N, D], [N, D] -> [N]\n",
    "vvdot = torch.vmap(vdot)      # [N, D, C] [ N, D, C ] -> [N, D]\n",
    "x, y = torch.ones(3, 2, 5), torch.ones(3, 2, 5)\n",
    "vvdot(x, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "batch_size, feature_size = 3, 5\n",
    "weights = torch.randn(feature_size, requires_grad=True)\n",
    "\n",
    "model = lambda features: features.dot(weights).relu()\n",
    "\n",
    "examples = torch.randn(batch_size, feature_size)\n",
    "model = torch.vmap(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "<function __main__.<lambda>(features)>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.0000, 0.0000, 0.6167], grad_fn=<ReluBackward0>)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(examples)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Setup\n",
    "N = 5\n",
    "f = lambda x: x ** 2\n",
    "x = torch.randn(N, requires_grad=True)\n",
    "y = f(x)\n",
    "I_N = torch.eye(N)\n",
    "\n",
    "# vectorized gradient computation\n",
    "vjp = lambda v: torch.autograd.grad(y, x, v)\n",
    "jacobian = torch.vmap(vjp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[ 3.4172, -0.0000, -0.0000, -0.0000,  0.0000],\n         [ 0.0000, -1.0290, -0.0000, -0.0000,  0.0000],\n         [ 0.0000, -0.0000, -1.6843, -0.0000,  0.0000],\n         [ 0.0000, -0.0000, -0.0000, -0.6492,  0.0000],\n         [ 0.0000, -0.0000, -0.0000, -0.0000,  0.0559]]),)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(I_N)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "class Var:\n",
    "  def __init__(self, val, grad_fn=lambda: []):\n",
    "    self.v, self.grad_fn = val, grad_fn\n",
    "  def __add__(self, other):\n",
    "    return Var(self.v + other.v,\n",
    "      lambda: [(self, 1.0), (other, 1.0)])\n",
    "  def __mul__(self, other):\n",
    "    return Var(self.v * other.v,\n",
    "      lambda: [(self, other.v), (other, self.v)])\n",
    "  def grad(self, bp = 1.0, dict = {}):\n",
    "    dict[self] = dict.get(self, 0) + bp\n",
    "    for input, val in self.grad_fn():\n",
    "        input.grad(val * bp, dict)\n",
    "    return dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Var(1.)\n",
    "y = Var(1.)\n",
    "f = x * x * x * x + y\n",
    "f.grad()[y]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "2.0"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.v"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}